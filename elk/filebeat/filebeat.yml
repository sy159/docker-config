# 具体参数配置直接看官网：https://www.elastic.co/guide/en/beats/filebeat/current/configuring-howto-filebeat.html

filebeat.inputs:
- type: filestream
  id: access_json_logs
  enabled: true
  paths:
    - /var/logs/access/*.log
  fields:
    source: access
    env: dev
  # json字段的设置
  json.keys_under_root: true
  json.add_error_key: true
  json.overwrite_keys: true

- type: filestream
  id: error_logs
  enabled: true
  paths:
    - /var/logs/error/*.log
  parsers:
    - multiline:
        type: pattern
        pattern: '^[0-9]{4}-[0-9]{2}-[0-9]{2}'  # 匹配的正则表达式，匹配时间开头
        negate: true  # 是否取反，即当不以日期格式开头时
        match: after  # 匹配规则，读取的行不以日期开头时，合并到以日期开头为一行。例如堆栈异常多行信息应当合并为一行消息
  fields:
    source: error
    env: dev


output.elasticsearch:
  hosts: [ "http://192.168.0.107:9200"]  # 事件将按循环顺序分发到这些节点。如果一个节点无法访问，事件将自动发送到另一个节点，不是每个节点都发送！！！
  username: "elastic"
  password: "zx.123"
  indices:
    - index: "log-access-%{+yyyy.MM.dd}"  # 是否需要根据时间分割%{+yyyy.MM.dd}
      when.equals:
        fields:
          source: "access"
    - index: "log-error-%{+yyyy.MM.dd}"
      when.equals:
        fields.source: "error"

processors:
  - drop_fields:
      fields: ["agent.ephemeral_id", "agent.name", "agent.version", "ecs.version", "host.name", "log.file.device_id",
               "log.file.inode", "log.file.path", "log.flags", "log.offset", "agent.type", "input.type"]
